---
title: 'Supplementary material 2: Sensitivity of results to inclusion of additional auxiliaries'
author: "Rob Boyd"
date: "13 March 2023"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Purpose of this document

The purpose of this document is to demonstrate that including additional auxiliary variables does not improve estimates of mean occupancy or the time trend between them. In fact, it barely changes the results at all. The three additional auxiliaries are the first and second principal components of climate space in Britain and soil pH. 

I do not provide any text beyond this introductory spiel in this document. The reason is that the code is  explained in plain English in supplementary material one. The code here is roughly identical; the only major difference is that I do not drop the three additional auxiliary variables. Looking at the figures at the bottom of the document, it is clear that the results are very similar to those obtained when the three auxiliaries are omitted. 

```{r warnings = FALSE}
library(raster)
library(ggplot2)
library(survey)
library(rstanarm)
library(PracTools)
library(reshape2)
library(dplyr)
library(caret)
library(boot)

## load population data
pop <- read.csv("W:/PYWELL_SHARED/Pywell Projects/BRC/Rob Boyd/NERC_exploring_frontiers/Data/all_data.csv")

pop <- pop[complete.cases(pop), ]

pop_disc <- pop

names(pop_disc)

## pull out the auxiliary data for the whole population
pop_aux_cont <- pop_disc[,c(5:11,14)]

## for reasons that will become clear later, we need to discretize the auxiliary data in pop
for (i in c(5,8,9,10,11,14)) {

  q <- as.numeric(quantile(pop_disc[,i], probs = c(0,0.33,0.66,1)))

  print(q)
  
  pop_disc[,i] <- cut(pop_disc[,i], 
                 breaks = q,
                 labels = FALSE,
                 include.lowest = TRUE,
                 right = TRUE)
  
  pop_disc[,i] <- as.numeric(pop_disc[,i])
  
}

## we'll make PA and open access land coverage binary 
pop_disc$openAccessGB <- ifelse(pop$openAccessGB > 0, 1, 0)

pop_disc$allPACoverage <- ifelse(pop$allPACoverage > 0, 1, 0)

## pull out columns relevant to period 1
names(pop)
pop_p1 <- pop[,c(1,3,5,6,7,8,9,10,11,12,14)]

pop_disc_p1 <- pop_disc[,c(1,3,5,6,7,8,9,10,11,12,14)]

## and period 2
pop_p2 <- pop[,c(2,4,5,6,7,8,9,10,11,13,14)]

pop_disc_p2 <- pop_disc[,c(2,4,5,6,7,8,9,10,11,13,14)]

## pull out sampled rows for periods 1 and 2
samp_disc_p1 <- pop_disc_p1[pop_disc_p1$sampled_units_1987.1999 == 1, ]

samp_disc_p2 <- pop_disc_p2[pop_disc_p2$sampled_units_2010.2019 == 1, ]

## pull out the auxiliary data for the whole population
pop_aux <- pop_disc[,c(5:11,14)]

## calculate the population means
pop_mean_p1 <- mean(pop_p1$heather_true_dist_1987.1999);pop_mean_p1

pop_mean_p2 <- mean(pop_p2$heather_true_dist_2010.2019);pop_mean_p2

## now set up survey designs using the survey package to construct estimators
design_p1 <- svydesign(ids=~0,
                       data = samp_disc_p1)

design_p2 <- svydesign(ids=~0,
                       data = samp_disc_p2)

## calculate sample means
samp_mean_p1 <- svymean(design = design_p1,
                        x=~heather_true_dist_1987.1999)

samp_mean_p2 <- svymean(design = design_p2,
                        x=~heather_true_dist_2010.2019)

## and their confidence intervals
samp_mean_p1_conf <- confint(object = samp_mean_p1,
                             level = 0.95)

samp_mean_p2_conf <- confint(object = samp_mean_p2,
                             level = 0.95)

## now calculate a weighted mean
## first create a new survey design with the estimated inclusion probabilities
weighted_design_p1 <- svydesign(ids=~0,
                                data = samp_disc_p1,
                                probs=~inclusionProbs_1987.1999)

weighted_design_p2 <- svydesign(ids=~0,
                                data = samp_disc_p2,
                                probs=~inclusionProbs_2010.2019)

## then get the weighted sample means
weighted_samp_mean_p1 <- svymean(design = weighted_design_p1,
                                 x=~heather_true_dist_1987.1999);weighted_samp_mean_p1

weighted_samp_mean_p2 <- svymean(design = weighted_design_p2,
                                 x=~heather_true_dist_2010.2019);weighted_samp_mean_p2

## and their confidence intervals 
weighted_samp_mean_p1_conf <- confint(object = weighted_samp_mean_p1,
                                      level = 0.95)

weighted_samp_mean_p2_conf <- confint(object = weighted_samp_mean_p2,
                                      level = 0.95)

## next we want to postratify. We use the auxiliary data from earlier
## first, cross the covariates to get the poststrata
cells <- data.frame(table(pop_aux))

cells$Freq[cells$Freq==0] <- 1

cellsSamp <- data.frame(table(samp_disc_p1[,c(3:7,9)]))


## now poststratify 
ps_design_p1 <- survey::postStratify(design = design_p1,
                             strata = samp_disc_p1[,c(3:9,11)],
                             population = cells,
                             partial = T)

ps_design_p2 <- survey::postStratify(design = design_p2,
                             strata = samp_disc_p2[,c(3:9,11)],
                             population = cells,
                             partial = T)

## and get the weighted mean across poststrata
ps_samp_mean_p1 <- svymean(design = ps_design_p1,
                           x=~heather_true_dist_1987.1999,
                           na.rm = T);ps_samp_mean_p1

ps_samp_mean_p2 <- svymean(design = ps_design_p2,
                                 x=~heather_true_dist_2010.2019);ps_samp_mean_p2

## and their confidence intervals
ps_samp_mean_p1_conf <- confint(object = ps_samp_mean_p1,
                                level = 0.95)

ps_samp_mean_p2_conf <- confint(object = ps_samp_mean_p2,
                                level = 0.95)

## another estimator is regression-based
## first, calculate sums of the auxiliary variables
aux_tots <- c(nrow(pop_aux_cont), colSums(pop_aux_cont))

names(aux_tots)[1] <- "(Intercept)"

## create new designs with the continuous rather than discretized auxiliary variables
samp_p1 <- pop_p1[pop_p1$sampled_units_1987.1999 == 1, ]

samp_p2 <- pop_p2[pop_p2$sampled_units_2010.2019 == 1, ]

pre_calib_design_p1 <- svydesign(ids=~0,
                       data = samp_p1)

pre_calib_design_p2 <- svydesign(ids=~0,
                       data = samp_p2)

## now calibrate 
calib_design_p1 <- calibrate(design = pre_calib_design_p1,
                             formula = ~ 
                               road_length_299_neighbours + postcode_density_299_neighbours + openAccessGB + allPACoverage + 
                               UKelv + X_3 + X_1 + layer,
                             population = aux_tots,
                             calfun="linear")

sum(weights(calib_design_p1))

summary(weights(calib_design_p1))

sp_samp_mean_p1 <- svymean(~heather_true_dist_1987.1999, design=calib_design_p1)

calib_design_p2 <- calibrate(design = pre_calib_design_p2,
                             formula = ~ 
                               road_length_299_neighbours + postcode_density_299_neighbours + openAccessGB + allPACoverage + 
                                UKelv + X_3 + X_1 + layer,
                             population = aux_tots,
                             calfun="linear")

sum(weights(calib_design_p2))

summary(weights(calib_design_p2))

sp_samp_mean_p2 <- svymean(~heather_true_dist_2010.2019, design=calib_design_p2)

## and the confidence intervals 
sp_samp_mean_p1_conf <- confint(object = sp_samp_mean_p1,
                                level = 0.95)

sp_samp_mean_p2_conf <- confint(object = sp_samp_mean_p2,
                                level = 0.95)


## let's plot some of the estimates so far
plotDat <- data.frame(p = c(1,2,1,2,1,2,1,2,1,2),
                      est = c(pop_mean_p1[1], pop_mean_p2[1], samp_mean_p1[1], samp_mean_p2[1], ps_samp_mean_p1[1], ps_samp_mean_p2[1], weighted_samp_mean_p1[1], weighted_samp_mean_p2[1], sp_samp_mean_p1[1], sp_samp_mean_p2[1]),
                      type = c("Population", "Population", "Sample", "Sample", "Poststratified", "Poststratified", "Quasi-rand", "Quasi-rand", "Superpopulation", "Superpopulation"),
                      lower = c(pop_mean_p1[1], pop_mean_p2[1], samp_mean_p1_conf[1], samp_mean_p2_conf[1], ps_samp_mean_p1_conf[1], ps_samp_mean_p2_conf[1], weighted_samp_mean_p1_conf[1], weighted_samp_mean_p2_conf[1], sp_samp_mean_p1_conf[1], sp_samp_mean_p2_conf[1]),
                      upper = c(pop_mean_p1[2], pop_mean_p2[2], samp_mean_p1_conf[2], samp_mean_p2_conf[2], ps_samp_mean_p1_conf[2], ps_samp_mean_p2_conf[2], weighted_samp_mean_p1_conf[2], weighted_samp_mean_p2_conf[2], sp_samp_mean_p1_conf[2], sp_samp_mean_p2_conf[2]))


ggplot(data = plotDat, aes(x = p, y = est, colour = type, fill = type)) +
  geom_point() +
  geom_line() +
  theme_linedraw() +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.15, colour = NA) +
  labs(x = "",
       y = "Estimate",
       fill = "",
       colour = "") +
  scale_x_continuous(breaks = c(1,2), labels = c("1987-1999", "2010-2019")) +
  theme(text=element_text(size = 20)) +
  ylim(c(0.2,0.4))


## now let's look at the trends 
trends <- lapply(unique(plotDat$type),
                 function(x) {
                   data.frame(difference = plotDat$est[plotDat$p == 2 & plotDat$type == x] - plotDat$est[plotDat$p == 1 & plotDat$type == x],
                              estimator = x)
                 })

trends <- do.call("rbind", trends)

## and the confidence intervals for the trends 

## sample mean 
sample_mean_se <- sqrt(SE(ps_samp_mean_p1)^2 + SE(ps_samp_mean_p2)^2)

sample_mean_upper <- (samp_mean_p2 - samp_mean_p1) + 1.96 * sample_mean_se

sample_mean_lower <- (samp_mean_p2 - samp_mean_p1) - 1.96 * sample_mean_se

## quasi-randomisation 
weighted_mean_se <- sqrt(SE(weighted_samp_mean_p1)^2 + SE(weighted_samp_mean_p2)^2)

weighted_mean_upper <- (weighted_samp_mean_p2 - weighted_samp_mean_p1) + 1.96 * weighted_mean_se

weighted_mean_lower <- (weighted_samp_mean_p2 - weighted_samp_mean_p1) - 1.96 * weighted_mean_se

## poststratification
ps_mean_se <- sqrt(SE(ps_samp_mean_p1)^2 + SE(ps_samp_mean_p2)^2)

ps_mean_upper <- (ps_samp_mean_p2 - ps_samp_mean_p1) + 1.96 * ps_mean_se

ps_mean_lower <- (ps_samp_mean_p2 - ps_samp_mean_p1) - 1.96 * ps_mean_se

## superpopulation
sp_mean_se <- sqrt(SE(sp_samp_mean_p1)^2 + SE(sp_samp_mean_p2)^2)

sp_mean_upper <- (sp_samp_mean_p2 - sp_samp_mean_p1) + 1.96 * sp_mean_se

sp_mean_lower <- (sp_samp_mean_p2 - sp_samp_mean_p1) - 1.96 * sp_mean_se

head(trends)

trends$lower <- c(NA, sample_mean_lower, ps_mean_lower, weighted_mean_lower, sp_mean_lower)

trends$upper <- c(NA, sample_mean_upper, ps_mean_upper, weighted_mean_upper, sp_mean_upper)

ggplot(data = trends, aes(x = difference, y = estimator)) +
         geom_point() + 
         theme_linedraw() +
         geom_vline(xintercept = 0) +
  labs(x = "Trend",
       y = "") +
  geom_errorbar(aes(xmin = lower, xmax = upper, width = .2)) +
  theme(text=element_text(size = 20))

```